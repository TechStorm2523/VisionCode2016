These are the resources used for vision processing this year:
(We used GRIP, a way to process images in an external program, then send them to the roborio via NetworkTables)


https://wpilib.screenstepslive.com/s/4485/m/50711/l/481750-using-grip-for-the-2016-game
https://github.com/WPIRoboticsProjects/GRIP/wiki/Tutorial:-Deploy-to-the-Robot
https://github.com/WPIRoboticsProjects/GRIP/wiki/Tutorial:-Run-GRIP-from-a-CPP-or-Java-FRC-program
https://github.com/WPIRoboticsProjects/GRIP-SmartDashboard/releases
